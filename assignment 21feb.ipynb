{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be546e6-1758-4967-92b6-2467a16caa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a  database so that it can be used in various applications. \n",
    "Web Scrapers can extract all the data on particular sites or the specific data that a user wants. Ideally, it’s best if you specify the data you want so that the web scraper only extracts that data quickly. For example, you might want to scrape an Amazon page for the types of juicers available, but you might only want the data about the models of different juicers and not the customer reviews. \n",
    "So, when a web scraper needs to scrape a site, first the URLs are provided. Then it loads all the HTML code for those sites and a more advanced scraper might even extract all the CSS and Javascript elements as well. Then the scraper obtains the required data from this HTML code and outputs this data in the format specified by the user. Mostly, this is in the form of an Excel spreadsheet or a CSV file, but the data can also be saved in other formats, such as a JSON file.\n",
    "What is Web Scraping used for?\n",
    "Web Scraping has multiple applications across various industries. Let’s check out some of these now!\n",
    "\n",
    "1. Price Monitoring\n",
    "Web Scraping can be used by companies to scrap the product data for their products and competing products as well to see how it impacts their pricing strategies. Companies can use this data to fix the optimal pricing for their products so that they can obtain maximum revenue.\n",
    "\n",
    "2. Market Research\n",
    "Web scraping can be used for market research by companies. High-quality web scraped data obtained in large volumes can be very helpful for companies in analyzing consumer trends and understanding which direction the company should move in the future. \n",
    "\n",
    "3. News Monitoring\n",
    "Web scraping news sites can provide detailed reports on the current news to a company. This is even more essential for companies that are frequently in the news or that depend on daily news for their day-to-day functioning. After all, news reports can make or break a company in a single day!\n",
    "\n",
    "4. Sentiment Analysis\n",
    "If companies want to understand the general sentiment for their products among their consumers, then Sentiment Analysis is a must. Companies can use web scraping to collect data from social media websites such as Facebook and Twitter as to what the general sentiment about their products is. This will help them in creating products that people desire and moving ahead of their competition.\n",
    "\n",
    "5. Email Marketing\n",
    "Companies can also use Web scraping for email marketing. They can collect Email ID’s from various sites using web scraping and then send bulk promotional and marketing Emails to all the people owning these Email ID’s'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef933d81-8d25-4ffb-8af0-c5d364845b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q2. What are the different methods used for Web Scraping?\n",
    "render_template\n",
    "requests\n",
    "beautifulsoap\n",
    "urlopen\n",
    "replace\n",
    "read\n",
    "findall\n",
    "pymongo'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940f1191-6588-42fc-a4d5-9e81b6dfb2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q3. What is Beautiful Soup? Why is it used?\n",
    "Beautiful Soup is a Python library used to pull the data out of HTML and XML files for web scraping purposes. It produces a parse tree from page source code that can be utilized to drag data hierarchically and more legibly.''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85c76d5-7f14-4d80-a010-d71e8cdce3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q4. Why is flask used in this Web Scraping project?\n",
    "flask is used to create web api to fetch data and store it in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768b9584-6e03-4d5d-8ba3-bedae65b3e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "2 aws services used..one is code pipleline and other is elastic beanstalk.\n",
    "AWS CodePipeline, a service that builds, tests, and deploys your code every time there is a code change. it helps to  use your GitHub account, an Amazon Simple Storage Service (Amazon S3) bucket, or an AWS CodeCommit repository as the source location for the sample app’s code. it will also use AWS Elastic Beanstalk as the deployment target for the sample app. the completed pipeline will be able to detect changes made to the source repository containing the sample app and then automatically update your live sample app.\n",
    "Continuous deployment allows you to deploy revisions to a production environment automatically without explicit approval from a developer, making the entire software release process automated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
